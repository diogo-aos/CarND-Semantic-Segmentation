{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 10\n",
    "DROPOUT_RATE = 0.5\n",
    "MODEL_PATH = '/tmp/model.ckpt'\n",
    "NOTES = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess as sp\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check TensorFlow Version                                                                                                                                              \n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU                                                                                                                                                       \n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_path = '/home/diogoaos/P2/CarND-Semantic-Segmentation/data/vgg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load vgg: Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"                                                                                                                                                                 \n",
    "    Load Pretrained VGG Model into TensorFlow.                                                                                                                          \n",
    "    :param sess: TensorFlow Session                                                                                                                                     \n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"                                                                                   \n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)                                                               \n",
    "    \"\"\"\n",
    "    # TODO: Implement function                                                                                                                                          \n",
    "    #   Use tf.saved_model.loader.load to load the model and weights                                                                                                    \n",
    "    vgg_tag = 'vgg16'\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'                                                                                                                         \n",
    "    \n",
    "    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "    g = tf.get_default_graph()\n",
    "    input_layer = g.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    keep_prob = g.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    l3 = g.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    l4 = g.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    l7 = g.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return input_layer, keep_prob, l3, l4, l7\n",
    "print('load vgg: ', end='')\n",
    "tests.test_load_vgg(load_vgg, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"                                                                                                                                                                 \n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.                                                                       \n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output                                                                                                             \n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output                                                                                                             \n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output                                                                                                             \n",
    "    :param num_classes: Number of classes to classify                                                                                                                   \n",
    "    :return: The Tensor for the last layer of output                                                                                                                    \n",
    "    \"\"\"\n",
    "    # at the end of VGG16, the image has been downsampled to 1/32th of original size\n",
    "    # Part1 (upsample 2x, final=2x):\n",
    "    #   conv 1x1 of layer7\n",
    "    #   upsample 2x previous\n",
    "    #   conv 1x1 layer4\n",
    "    #   add them\n",
    "    # Part2 (upsample 2x, final=4x):\n",
    "    #   upsample 2x Part1\n",
    "    #   conv 1x1 layer3\n",
    "    #   add them\n",
    "    # Part3 (upsample 8x, final=32x):\n",
    "    #   upsample Part2 8x\n",
    "    \n",
    "    # TODO: Implement function\n",
    "    # 1 by 1 convolution from VGG output\n",
    "    # stride is what is upsmapling, padding must be same, size may change\n",
    "    # use regulizer to everylayer according to Aron\n",
    "    # the regulizer penalizes when the weights get too large\n",
    "    l7_conv_1x1 = tf.layers.conv2d(vgg_layer7_out,\n",
    "                                filters=num_classes,\n",
    "                                kernel_size=1,\n",
    "                                strides=(1,1),\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    #fcn32 = tf.layers.conv2d_transpose(l7_conv_1x1,\n",
    "    #                                    filters=num_classes,\n",
    "    #                                    kernel_size=64,\n",
    "    #                                    strides=32,\n",
    "    #                                    padding='same',\n",
    "    #                                    kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    l4_conv_1x1 = tf.layers.conv2d(vgg_layer4_out,\n",
    "                                filters=num_classes,\n",
    "                                kernel_size=1,\n",
    "                                strides=(1,1),\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    l3_conv_1x1 = tf.layers.conv2d(vgg_layer3_out,\n",
    "                                filters=num_classes,\n",
    "                                kernel_size=1,\n",
    "                                strides=(1,1),\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    # second layer is transposed convolution from 1 by 1 convolution\n",
    "    # we want to upsample x2 and then skip layer 4\n",
    "    fcn16 = tf.layers.conv2d_transpose(l7_conv_1x1,\n",
    "                                        filters=num_classes,\n",
    "                                        kernel_size=4,\n",
    "                                        strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    fcn16 = tf.add(fcn16, l4_conv_1x1)\n",
    "    #fcn16 = tf.layers.conv2d_transpose(fcn16,\n",
    "    #                                    filters=num_classes,\n",
    "    #                                    kernel_size=32,\n",
    "    #                                    strides=16,\n",
    "    #                                    padding='same',\n",
    "    #                                    kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    # next we want to again upsample x2 (total 4x),\n",
    "    # skip upsampled layer 4 (upsample x2)\n",
    "    # skip layer 3\n",
    "    fcn8 = tf.layers.conv2d_transpose(fcn16,\n",
    "                                        filters=num_classes,\n",
    "                                        kernel_size=4,\n",
    "                                        strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    fcn8 = tf.add(fcn8, l3_conv_1x1)\n",
    "    fcn8 = tf.layers.conv2d_transpose(fcn8,\n",
    "                                        filters=num_classes,\n",
    "                                        kernel_size=16,\n",
    "                                        strides=8,\n",
    "                                        padding='same',\n",
    "                                        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    return fcn8\n",
    "print('layers: ', end='')\n",
    "tests.test_layers(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-1a7a0e3b592b>:13: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"                                                                                                                                                                 \n",
    "    Build the TensorFLow loss and optimizer operations.                                                                                                                 \n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network                                                                                             \n",
    "    :param correct_label: TF Placeholder for the correct label image                                                                                                    \n",
    "    :param learning_rate: TF Placeholder for the learning rate                                                                                                          \n",
    "    :param num_classes: Number of classes to classify                                                                                                                   \n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)                                                                                                            \n",
    "    \"\"\"\n",
    "    # logits : 2D tensor; rows=pixels; columns=pixel classes\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    correct_label = tf.reshape(correct_label, (-1,num_classes))\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label)\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    train_op = optimizer.minimize(loss_operation)\n",
    "    return logits, train_op, loss_operation\n",
    "tests.test_optimize(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results():\n",
    "    time_str = datetime.now().strftime(\"%d_%m_%Y__%H_%M\")\n",
    "    out_dir = 'results/' + time_str\n",
    "    os.mkdir(out_dir)\n",
    "    file_out = os.path.join(out_dir, time_str + '.txt')\n",
    "    plot_fn = os.path.join(out_dir, 'loss.png')\n",
    "    \n",
    "    FPS = 4\n",
    "    video_avi_fn = os.path.join(out_dir, 'inference.avi')\n",
    "    video_mp4_fn = os.path.join(out_dir, 'inference.mp4')\n",
    "\n",
    "    \n",
    "    with open(file_out, 'w') as f:\n",
    "        f.write(\"epochs={}, learning_rate={}, batch_size={}, dropout_rate={}\\n\".format(\n",
    "                 EPOCHS, LEARNING_RATE, BATCH_SIZE, DROPOUT_RATE))\n",
    "        f.write('notes:' + NOTES + '\\n')\n",
    "        \n",
    "    def update(epoch, bs, loss):\n",
    "        with open(file_out, 'a') as f:\n",
    "            f.write('epoch={}\\n'.format(epoch))\n",
    "            f.write('batch_sizes={}\\n'.format(bs))\n",
    "            f.write('loss={}\\n'.format(loss))\n",
    "    \n",
    "\n",
    "    def save_plot():\n",
    "        with open(file_out, 'r') as f:\n",
    "            header = f.readline()\n",
    "            data = f.read()\n",
    "        data = data.split('epoch=')[1:]\n",
    "        epoch_loss = []\n",
    "        for d in data:\n",
    "            bs_idx_start = d.find('batch_sizes=[') + len('batch_sizes=[')\n",
    "            bs_idx_end = d.find(']\\nloss')\n",
    "            l_idx_start = d.find('loss=[') + len('loss=[')\n",
    "            l_idx_end = d.find(']', l_idx_start)\n",
    "            bs = d[bs_idx_start: bs_idx_end]\n",
    "            bs = list(map(int, bs.split(',')))\n",
    "            l = d[l_idx_start: l_idx_end]\n",
    "            l = list(map(float, l.split(',')))\n",
    "            assert len(bs) == len(l)\n",
    "            total_images = sum(bs)\n",
    "            total_loss = sum(l)\n",
    "            average_loss = total_loss / total_images\n",
    "            epoch_loss.append(average_loss)\n",
    "        \n",
    "        plt.plot(epoch_loss, label='training')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('mean cross entropy loss')\n",
    "        plt.title(header)\n",
    "        plt.legend()\n",
    "        plt.savefig(plot_fn)\n",
    "        \n",
    "    def save_video():\n",
    "        test_out_dirs = os.listdir('runs/')\n",
    "        test_out_dir = os.path.join('runs', test_out_dirs[-1])\n",
    "        images_fn = os.listdir(test_out_dir)\n",
    "        images_fn = sorted(images_fn)\n",
    "        \n",
    "        def process(im, txt):\n",
    "            height, width, channel = im.shape\n",
    "            text_height = 40\n",
    "            img = np.zeros((height + text_height,width,channel), np.uint8)\n",
    "            img[0:height] = im[:]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(img, txt,(int(width/2) - int(width/5),height + text_height - 10), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "            return img\n",
    "        \n",
    "        im = cv2.imread(os.path.join(test_out_dir, images_fn[0]))\n",
    "        im = process(im, 'X')\n",
    "        height, width, channel = im.shape\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP42')\n",
    "        video = cv2.VideoWriter(video_avi_fn, fourcc, float(FPS), (width, height))\n",
    "\n",
    "        for im_fn in images_fn:\n",
    "            frame = cv2.imread(os.path.join(test_out_dir, im_fn))\n",
    "            video.write(process(frame, im_fn))\n",
    "        video.release()\n",
    "        \n",
    "        sp.Popen(['ffmpeg', '-i', video_avi_fn, video_mp4_fn])\n",
    "        \n",
    "        for d in test_out_dirs:\n",
    "            shutil.rmtree(os.path.join('runs', d))\n",
    "    \n",
    "    return update, save_plot, save_video, out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "update, save_plot, save_video, out_dir = save_results()\n",
    "MODEL_PATH = os.path.join(out_dir, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 166.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./data/vgg/variables/variables\n",
      "WARNING:tensorflow:From /home/diogoaos/p2/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from ./data/vgg/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from results/29_03_2019__18_38/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \"\"\"                                                                                                                                                                 \n",
    "    Train neural network and print out the loss during training.                                                                                                        \n",
    "    :param sess: TF Session                                                                                                                                             \n",
    "    :param epochs: Number of epochs                                                                                                                                     \n",
    "    :param batch_size: Batch size                                                                                                                                       \n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)                                                             \n",
    "    :param train_op: TF Operation to train the neural network                                                                                                           \n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss                                                                                                         \n",
    "    :param input_image: TF Placeholder for input images                                                                                                                 \n",
    "    :param correct_label: TF Placeholder for label images                                                                                                               \n",
    "    :param keep_prob: TF Placeholder for dropout keep probability                                                                                                       \n",
    "    :param learning_rate: TF Placeholder for learning rate                                                                                                              \n",
    "    \"\"\"\n",
    "    pbar = tqdm(total=epochs)\n",
    "    all_size = []\n",
    "    all_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_batch_size = []\n",
    "        epoch_loss = []\n",
    "        for image, label in get_batches_fn(batch_size):\n",
    "            # create feed dict: input image, correct label, keep prob, learning rate\n",
    "            # loss = session.run\n",
    "            feed_dict = {input_image: image,\n",
    "                         correct_label: label,\n",
    "                         keep_prob: DROPOUT_RATE,\n",
    "                         learning_rate: LEARNING_RATE}\n",
    "            _, loss = sess.run([train_op, cross_entropy_loss], feed_dict=feed_dict)\n",
    "            epoch_batch_size.append(len(image))\n",
    "            epoch_loss.append(loss)\n",
    "        all_loss.append(epoch_batch_size)\n",
    "        all_loss.append(epoch_loss)\n",
    "        print('epoch {}/{} | {} images | loss {}'.format(epoch, epochs,sum(epoch_batch_size), sum(epoch_loss) / sum(epoch_batch_size)))\n",
    "        update(epoch, epoch_batch_size, epoch_loss)\n",
    "        pbar.update(1)\n",
    "    pass\n",
    "tests.test_train_nn(train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    num_classes = 2\n",
    "    image_shape = (160, 576)  # KITTI dataset uses 160x576 images                                                                                                       \n",
    "    data_dir = './data'\n",
    "    runs_dir = './runs'\n",
    "    tests.test_for_kitti_dataset(data_dir)\n",
    "\n",
    "    # Download pretrained vgg model                                                                                                                                     \n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "\n",
    "    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.                                                                             \n",
    "    # You'll need a GPU with at least 10 teraFLOPS to train on.                                                                                                         \n",
    "    #  https://www.cityscapes-dataset.com/\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print('setup...')\n",
    "        label_layer = tf.placeholder(tf.int32, (None, None, None, num_classes), name='gt_label')\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        \n",
    "        # Path to vgg model                                                                                                                                             \n",
    "        vgg_path = os.path.join(data_dir, 'vgg')\n",
    "        # Create function to get batches                                                                                                                                \n",
    "        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
    "\n",
    "        # OPTIONAL: Augment Images for better results                                                                                                                   \n",
    "        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network                                                        \n",
    "\n",
    "        # TODO: Build NN using load_vgg, layers, and optimize function\n",
    "        input_image, keep_prob, layer3, layer4, layer7 = load_vgg(sess, vgg_path)\n",
    "        layer_output = layers(layer3, layer4, layer7, num_classes)\n",
    "\n",
    "        # TODO: Train NN using the train_nn function\n",
    "        \n",
    "        logits, train_op, cross_entropy_loss = optimize(layer_output, label_layer, learning_rate, num_classes )\n",
    "        \n",
    "        print('training...')\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        \n",
    "        train_nn(sess, EPOCHS, BATCH_SIZE, get_batches_fn, train_op, cross_entropy_loss,\n",
    "                 input_image, label_layer, keep_prob, learning_rate)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, MODEL_PATH)\n",
    "\n",
    "        print('inference on test images...')\n",
    "        helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)                                                         \n",
    "        \n",
    "        print('saving plot...')\n",
    "        save_plot()\n",
    "        print('saving video...')\n",
    "        save_video()\n",
    "\n",
    "        # OPTIONAL: Apply the trained model to a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [09:23<00:00, 18.77s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_on_image(sess, logits, keep_prob, image_input, image, image_shape):\n",
    "    \"\"\"\n",
    "    Generate test output using the test images\n",
    "    :param sess: TF session\n",
    "    :param logits: TF Tensor for the logits\n",
    "    :param keep_prob: TF Placeholder for the dropout keep probability\n",
    "    :param image_pl: TF Placeholder for the image placeholder\n",
    "    :param data_folder: Path to the folder that contains the datasets\n",
    "    :param image_shape: Tuple - Shape of image\n",
    "    :return: Output for for each test image\n",
    "    \"\"\"\n",
    "    image = scipy.misc.imresize(image, image_shape)\n",
    "\n",
    "    # Run inference\n",
    "    im_softmax = sess.run(\n",
    "        [tf.nn.softmax(logits)],\n",
    "        {keep_prob: 1.0, image_input: [image]})\n",
    "    # Splice out second column (road), reshape output back to image_shape\n",
    "    im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "    # If road softmax > 0.5, prediction is road\n",
    "    segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "    # Create mask based on segmentation to apply to original image\n",
    "    mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "    mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "    street_im = scipy.misc.toimage(image)\n",
    "    street_im.paste(mask, box=None, mask=mask)\n",
    "\n",
    "    return np.array(street_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_video(video_in_fn):\n",
    "    cap = cv2.VideoCapture(video_in_fn)\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return n_frames, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(video_in_fn):\n",
    "    cap = cv2.VideoCapture(video_in_fn)\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "        raise Exception(\"Error opening video stream or file\")\n",
    "\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        yield frame\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_videos = ['data/neuronios.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "vgg_path = os.path.join(data_dir, 'vgg')\n",
    "\n",
    "OUT_DIR = 'results/29_03_2019__14_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_fn, model_dir, out_dir_param):\n",
    "    model_fn = os.path.join(model_dir, 'model.ckpt')\n",
    "    video_in_fn_suffix = video_fn.split('/')[-1]\n",
    "    video_in_fn_suffix = video_in_fn_suffix.split('.')[0]\n",
    "    video_out_fn = os.path.join(out_dir_param, 'processed_' + video_in_fn_suffix + '.avi')\n",
    "\n",
    "    n_frames, fps = info_video(video_fn)\n",
    "    image_shape = (160, 576)\n",
    "    num_classes = 2\n",
    "    height, width = image_shape\n",
    "\n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # load model\n",
    "        input_image, keep_prob, layer3, layer4, layer7 = load_vgg(sess, vgg_path)\n",
    "        layer_output = layers(layer3, layer4, layer7, num_classes)\n",
    "        logits = tf.reshape(layer_output, (-1, num_classes))\n",
    "\n",
    "        # restore variables\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_fn)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP42')\n",
    "        video_out = cv2.VideoWriter(video_out_fn, fourcc, float(fps), (width, height))\n",
    "\n",
    "        video_in = load_video(video_fn)\n",
    "        pbar = tqdm(total=n_frames)\n",
    "        for frame in video_in:\n",
    "            inf_frame = inference_on_image(sess, logits, keep_prob, input_image, frame, image_shape)\n",
    "            video_out.write(inf_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "        video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/673 [00:00<?, ?it/s]\u001b[A/home/diogoaos/p2/lib/python3.5/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  if sys.path[0] == '':\n",
      "/home/diogoaos/p2/lib/python3.5/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/home/diogoaos/p2/lib/python3.5/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "\n",
      "  0%|          | 1/673 [00:00<02:13,  5.04it/s]\u001b[A\n",
      "  0%|          | 2/673 [00:00<02:04,  5.37it/s]\u001b[A\n",
      "  0%|          | 3/673 [00:00<01:59,  5.60it/s]\u001b[A\n",
      "  1%|          | 4/673 [00:00<01:55,  5.78it/s]\u001b[A\n",
      "  1%|          | 5/673 [00:00<01:52,  5.93it/s]\u001b[A\n",
      "  1%|          | 6/673 [00:00<01:51,  6.01it/s]\u001b[A\n",
      "  1%|          | 7/673 [00:01<01:51,  5.96it/s]\u001b[A\n",
      "  1%|          | 8/673 [00:01<01:50,  6.04it/s]\u001b[A\n",
      "  1%|▏         | 9/673 [00:01<01:49,  6.07it/s]\u001b[A\n",
      "  1%|▏         | 10/673 [00:01<01:47,  6.16it/s]\u001b[A\n",
      "  2%|▏         | 11/673 [00:01<01:47,  6.16it/s]\u001b[A\n",
      "  2%|▏         | 12/673 [00:01<01:46,  6.19it/s]\u001b[A\n",
      "  2%|▏         | 13/673 [00:02<01:46,  6.20it/s]\u001b[A\n",
      "  2%|▏         | 14/673 [00:02<01:45,  6.24it/s]\u001b[A\n",
      "  2%|▏         | 15/673 [00:02<01:45,  6.25it/s]\u001b[A\n",
      "  2%|▏         | 16/673 [00:02<01:45,  6.21it/s]\u001b[A\n",
      "  3%|▎         | 17/673 [00:02<01:45,  6.20it/s]\u001b[A\n",
      "  3%|▎         | 18/673 [00:02<01:46,  6.14it/s]\u001b[A\n",
      "  3%|▎         | 19/673 [00:03<01:46,  6.17it/s]\u001b[A\n",
      "  3%|▎         | 20/673 [00:03<01:45,  6.19it/s]\u001b[A\n",
      "  3%|▎         | 21/673 [00:03<01:45,  6.18it/s]\u001b[A\n",
      "  3%|▎         | 22/673 [00:03<01:45,  6.20it/s]\u001b[A\n",
      "  3%|▎         | 23/673 [00:03<01:44,  6.22it/s]\u001b[A\n",
      "  4%|▎         | 24/673 [00:03<01:44,  6.20it/s]\u001b[A\n",
      "  4%|▎         | 25/673 [00:04<01:45,  6.17it/s]\u001b[A\n",
      "  4%|▍         | 26/673 [00:04<01:44,  6.18it/s]\u001b[A\n",
      "  4%|▍         | 27/673 [00:04<01:44,  6.18it/s]\u001b[A\n",
      "  4%|▍         | 28/673 [00:04<01:44,  6.17it/s]\u001b[A\n",
      "  4%|▍         | 29/673 [00:04<01:44,  6.19it/s]\u001b[A\n",
      "  4%|▍         | 30/673 [00:04<01:43,  6.22it/s]\u001b[A\n",
      "  5%|▍         | 31/673 [00:05<01:43,  6.22it/s]\u001b[A\n",
      "  5%|▍         | 32/673 [00:05<01:43,  6.22it/s]\u001b[A\n",
      "  5%|▍         | 33/673 [00:05<01:43,  6.18it/s]\u001b[A\n",
      "  5%|▌         | 34/673 [00:05<01:44,  6.14it/s]\u001b[A\n",
      "  5%|▌         | 35/673 [00:05<01:43,  6.16it/s]\u001b[A\n",
      "  5%|▌         | 36/673 [00:05<01:43,  6.16it/s]\u001b[A\n",
      "  5%|▌         | 37/673 [00:06<01:43,  6.16it/s]\u001b[A\n",
      "  6%|▌         | 38/673 [00:06<01:43,  6.14it/s]\u001b[A\n",
      "  6%|▌         | 39/673 [00:06<01:43,  6.13it/s]\u001b[A\n",
      "  6%|▌         | 40/673 [00:06<01:43,  6.10it/s]\u001b[A\n",
      "  6%|▌         | 41/673 [00:06<01:44,  6.07it/s]\u001b[A\n",
      "  6%|▌         | 42/673 [00:06<01:43,  6.07it/s]\u001b[A\n",
      "  6%|▋         | 43/673 [00:06<01:43,  6.11it/s]\u001b[A\n",
      "  7%|▋         | 44/673 [00:07<01:42,  6.13it/s]\u001b[A\n",
      "  7%|▋         | 45/673 [00:07<01:43,  6.08it/s]\u001b[A\n",
      "  7%|▋         | 46/673 [00:07<01:42,  6.12it/s]\u001b[A\n",
      "  7%|▋         | 47/673 [00:07<01:43,  6.07it/s]\u001b[A\n",
      "  7%|▋         | 48/673 [00:07<01:45,  5.95it/s]\u001b[A\n",
      "  7%|▋         | 49/673 [00:07<01:43,  6.01it/s]\u001b[A\n",
      "  7%|▋         | 50/673 [00:08<01:42,  6.08it/s]\u001b[A\n",
      "  8%|▊         | 51/673 [00:08<01:41,  6.11it/s]\u001b[A\n",
      "  8%|▊         | 52/673 [00:08<01:41,  6.14it/s]\u001b[A\n",
      "  8%|▊         | 53/673 [00:08<01:40,  6.15it/s]\u001b[A\n",
      "  8%|▊         | 54/673 [00:08<01:40,  6.17it/s]\u001b[A\n",
      "  8%|▊         | 55/673 [00:08<01:40,  6.14it/s]\u001b[A\n",
      "  8%|▊         | 56/673 [00:09<01:40,  6.14it/s]\u001b[A\n",
      "  8%|▊         | 57/673 [00:09<01:40,  6.12it/s]\u001b[A\n",
      "  9%|▊         | 58/673 [00:09<01:40,  6.12it/s]\u001b[A\n",
      "  9%|▉         | 59/673 [00:09<01:40,  6.12it/s]\u001b[A\n",
      "  9%|▉         | 60/673 [00:09<01:40,  6.10it/s]\u001b[A\n",
      "  9%|▉         | 61/673 [00:09<01:39,  6.13it/s]\u001b[A\n",
      "  9%|▉         | 62/673 [00:10<01:39,  6.16it/s]\u001b[A\n",
      "  9%|▉         | 63/673 [00:10<01:39,  6.14it/s]\u001b[A\n",
      " 10%|▉         | 64/673 [00:10<01:38,  6.15it/s]\u001b[A\n",
      " 10%|▉         | 65/673 [00:10<01:38,  6.17it/s]\u001b[A\n",
      " 10%|▉         | 66/673 [00:10<01:38,  6.19it/s]\u001b[A\n",
      " 10%|▉         | 67/673 [00:10<01:37,  6.20it/s]\u001b[A\n",
      " 10%|█         | 68/673 [00:11<01:37,  6.20it/s]\u001b[A\n",
      " 10%|█         | 69/673 [00:11<01:38,  6.16it/s]\u001b[A\n",
      " 10%|█         | 70/673 [00:11<01:37,  6.17it/s]\u001b[A\n",
      " 11%|█         | 71/673 [00:11<01:38,  6.14it/s]\u001b[A\n",
      " 11%|█         | 72/673 [00:11<01:38,  6.08it/s]\u001b[A\n",
      " 11%|█         | 73/673 [00:11<01:38,  6.08it/s]\u001b[A\n",
      " 11%|█         | 74/673 [00:12<01:38,  6.10it/s]\u001b[A\n",
      " 11%|█         | 75/673 [00:12<01:38,  6.10it/s]\u001b[A\n",
      " 11%|█▏        | 76/673 [00:12<01:37,  6.12it/s]\u001b[A\n",
      " 11%|█▏        | 77/673 [00:12<01:37,  6.11it/s]\u001b[A\n",
      " 12%|█▏        | 78/673 [00:12<01:37,  6.12it/s]\u001b[A\n",
      " 12%|█▏        | 79/673 [00:12<01:37,  6.08it/s]\u001b[A\n",
      " 12%|█▏        | 80/673 [00:13<01:37,  6.07it/s]\u001b[A\n",
      " 12%|█▏        | 81/673 [00:13<01:37,  6.09it/s]\u001b[A\n",
      " 12%|█▏        | 82/673 [00:13<01:36,  6.09it/s]\u001b[A\n",
      " 12%|█▏        | 83/673 [00:13<01:36,  6.09it/s]\u001b[A\n",
      " 12%|█▏        | 84/673 [00:13<01:36,  6.09it/s]\u001b[A\n",
      " 13%|█▎        | 85/673 [00:13<01:36,  6.07it/s]\u001b[A\n",
      " 13%|█▎        | 86/673 [00:14<01:36,  6.11it/s]\u001b[A\n",
      " 13%|█▎        | 87/673 [00:14<01:35,  6.12it/s]\u001b[A\n",
      " 13%|█▎        | 88/673 [00:14<01:35,  6.13it/s]\u001b[A\n",
      " 13%|█▎        | 89/673 [00:14<01:34,  6.16it/s]\u001b[A\n",
      " 13%|█▎        | 90/673 [00:14<01:34,  6.18it/s]\u001b[A\n",
      " 14%|█▎        | 91/673 [00:14<01:35,  6.12it/s]\u001b[A\n",
      " 14%|█▎        | 92/673 [00:15<01:35,  6.11it/s]\u001b[A\n",
      " 14%|█▍        | 93/673 [00:15<01:34,  6.15it/s]\u001b[A\n",
      " 14%|█▍        | 94/673 [00:15<01:34,  6.14it/s]\u001b[A\n",
      " 14%|█▍        | 95/673 [00:15<01:34,  6.12it/s]\u001b[A\n",
      " 14%|█▍        | 96/673 [00:15<01:34,  6.10it/s]\u001b[A\n",
      " 14%|█▍        | 97/673 [00:15<01:34,  6.09it/s]\u001b[A\n",
      " 15%|█▍        | 98/673 [00:15<01:33,  6.14it/s]\u001b[A\n",
      " 15%|█▍        | 99/673 [00:16<01:33,  6.16it/s]\u001b[A\n",
      " 15%|█▍        | 100/673 [00:16<01:32,  6.17it/s]\u001b[A\n",
      " 15%|█▌        | 101/673 [00:16<01:32,  6.16it/s]\u001b[A\n",
      " 15%|█▌        | 102/673 [00:16<01:32,  6.16it/s]\u001b[A\n",
      " 15%|█▌        | 103/673 [00:16<01:32,  6.15it/s]\u001b[A\n",
      " 15%|█▌        | 104/673 [00:16<01:32,  6.16it/s]\u001b[A\n",
      " 16%|█▌        | 105/673 [00:17<01:31,  6.18it/s]\u001b[A\n",
      " 16%|█▌        | 106/673 [00:17<01:31,  6.18it/s]\u001b[A\n",
      " 16%|█▌        | 107/673 [00:17<01:31,  6.19it/s]\u001b[A\n",
      " 16%|█▌        | 108/673 [00:17<01:31,  6.20it/s]\u001b[A\n",
      " 16%|█▌        | 109/673 [00:17<01:31,  6.20it/s]\u001b[A\n",
      " 16%|█▋        | 110/673 [00:17<01:31,  6.16it/s]\u001b[A\n",
      " 16%|█▋        | 111/673 [00:18<01:31,  6.15it/s]\u001b[A\n",
      " 17%|█▋        | 112/673 [00:18<01:31,  6.15it/s]\u001b[A\n",
      " 17%|█▋        | 113/673 [00:18<01:31,  6.12it/s]\u001b[A\n",
      " 17%|█▋        | 114/673 [00:18<01:30,  6.15it/s]\u001b[A\n",
      " 17%|█▋        | 115/673 [00:18<01:30,  6.15it/s]\u001b[A\n",
      " 17%|█▋        | 116/673 [00:18<01:30,  6.15it/s]\u001b[A\n",
      " 17%|█▋        | 117/673 [00:19<01:30,  6.12it/s]\u001b[A\n",
      " 18%|█▊        | 118/673 [00:19<01:33,  5.91it/s]\u001b[A\n",
      " 18%|█▊        | 119/673 [00:19<01:32,  5.97it/s]\u001b[A\n",
      " 18%|█▊        | 120/673 [00:19<01:31,  6.03it/s]\u001b[A\n",
      " 18%|█▊        | 121/673 [00:19<01:31,  6.06it/s]\u001b[A\n",
      " 18%|█▊        | 122/673 [00:19<01:31,  6.03it/s]\u001b[A\n",
      " 18%|█▊        | 123/673 [00:20<01:30,  6.08it/s]\u001b[A\n",
      " 18%|█▊        | 124/673 [00:20<01:29,  6.11it/s]\u001b[A\n",
      " 19%|█▊        | 125/673 [00:20<01:29,  6.10it/s]\u001b[A\n",
      " 19%|█▊        | 126/673 [00:20<01:30,  6.07it/s]\u001b[A\n",
      " 19%|█▉        | 127/673 [00:20<01:29,  6.07it/s]\u001b[A\n",
      " 19%|█▉        | 128/673 [00:20<01:30,  6.05it/s]\u001b[A\n",
      " 19%|█▉        | 129/673 [00:21<01:30,  6.00it/s]\u001b[A\n",
      " 19%|█▉        | 130/673 [00:21<01:29,  6.04it/s]\u001b[A\n",
      " 19%|█▉        | 131/673 [00:21<01:29,  6.03it/s]\u001b[A\n",
      " 20%|█▉        | 132/673 [00:21<01:30,  5.98it/s]\u001b[A\n",
      " 20%|█▉        | 133/673 [00:21<01:30,  5.95it/s]\u001b[A\n",
      " 20%|█▉        | 134/673 [00:21<01:30,  5.99it/s]\u001b[A\n",
      " 20%|██        | 135/673 [00:22<01:29,  6.02it/s]\u001b[A\n",
      " 20%|██        | 136/673 [00:22<01:29,  5.99it/s]\u001b[A\n",
      " 20%|██        | 137/673 [00:22<01:29,  6.00it/s]\u001b[A\n",
      " 21%|██        | 138/673 [00:22<01:28,  6.02it/s]\u001b[A\n",
      " 21%|██        | 139/673 [00:22<01:28,  6.07it/s]\u001b[A\n",
      " 21%|██        | 140/673 [00:22<01:28,  6.03it/s]\u001b[A\n",
      " 21%|██        | 141/673 [00:23<01:28,  6.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 142/673 [00:23<01:28,  6.01it/s]\u001b[A\n",
      " 21%|██        | 143/673 [00:23<01:27,  6.04it/s]\u001b[A\n",
      " 21%|██▏       | 144/673 [00:23<01:27,  6.01it/s]\u001b[A\n",
      " 22%|██▏       | 145/673 [00:23<01:28,  5.96it/s]\u001b[A\n",
      " 22%|██▏       | 146/673 [00:23<01:28,  5.98it/s]\u001b[A\n",
      " 22%|██▏       | 147/673 [00:24<01:27,  6.04it/s]\u001b[A\n",
      " 22%|██▏       | 148/673 [00:24<01:27,  6.03it/s]\u001b[A\n",
      " 22%|██▏       | 149/673 [00:24<01:27,  5.99it/s]\u001b[A\n",
      " 22%|██▏       | 150/673 [00:24<01:26,  6.03it/s]\u001b[A\n",
      " 22%|██▏       | 151/673 [00:24<01:26,  6.01it/s]\u001b[A\n",
      " 23%|██▎       | 152/673 [00:24<01:26,  6.01it/s]\u001b[A\n",
      " 23%|██▎       | 153/673 [00:25<01:25,  6.06it/s]\u001b[A\n",
      " 23%|██▎       | 154/673 [00:25<01:25,  6.04it/s]\u001b[A\n",
      " 23%|██▎       | 155/673 [00:25<01:27,  5.92it/s]\u001b[A\n",
      " 23%|██▎       | 156/673 [00:25<01:26,  5.97it/s]\u001b[A\n",
      " 23%|██▎       | 157/673 [00:25<01:26,  5.97it/s]\u001b[A\n",
      " 23%|██▎       | 158/673 [00:25<01:25,  6.00it/s]\u001b[A\n",
      " 24%|██▎       | 159/673 [00:26<01:25,  6.03it/s]\u001b[A\n",
      " 24%|██▍       | 160/673 [00:26<01:24,  6.05it/s]\u001b[A\n",
      " 24%|██▍       | 161/673 [00:26<01:24,  6.05it/s]\u001b[A\n",
      " 24%|██▍       | 162/673 [00:26<01:24,  6.05it/s]\u001b[A\n",
      " 24%|██▍       | 163/673 [00:26<01:24,  6.02it/s]\u001b[A\n",
      " 24%|██▍       | 164/673 [00:26<01:24,  6.03it/s]\u001b[A\n",
      " 25%|██▍       | 165/673 [00:27<01:24,  6.03it/s]\u001b[A\n",
      " 25%|██▍       | 166/673 [00:27<01:24,  5.99it/s]\u001b[A\n",
      " 25%|██▍       | 167/673 [00:27<01:24,  6.01it/s]\u001b[A\n",
      " 25%|██▍       | 168/673 [00:27<01:23,  6.06it/s]\u001b[A\n",
      " 25%|██▌       | 169/673 [00:27<01:23,  6.06it/s]\u001b[A\n",
      " 25%|██▌       | 170/673 [00:27<01:23,  6.00it/s]\u001b[A\n",
      " 25%|██▌       | 171/673 [00:28<01:23,  6.00it/s]\u001b[A\n",
      " 26%|██▌       | 172/673 [00:28<01:24,  5.96it/s]\u001b[A\n",
      " 26%|██▌       | 173/673 [00:28<01:23,  5.96it/s]\u001b[A\n",
      " 26%|██▌       | 174/673 [00:28<01:23,  5.99it/s]\u001b[A\n",
      " 26%|██▌       | 175/673 [00:28<01:23,  5.96it/s]\u001b[A\n",
      " 26%|██▌       | 176/673 [00:28<01:22,  6.01it/s]\u001b[A\n",
      " 26%|██▋       | 177/673 [00:29<01:22,  5.99it/s]\u001b[A\n",
      " 26%|██▋       | 178/673 [00:29<01:22,  5.97it/s]\u001b[A\n",
      " 27%|██▋       | 179/673 [00:29<01:22,  5.96it/s]\u001b[A\n",
      " 27%|██▋       | 180/673 [00:29<01:22,  5.99it/s]\u001b[A\n",
      " 27%|██▋       | 181/673 [00:29<01:22,  5.99it/s]\u001b[A\n",
      " 27%|██▋       | 182/673 [00:29<01:22,  5.99it/s]\u001b[A\n",
      " 27%|██▋       | 183/673 [00:30<01:22,  5.97it/s]\u001b[A\n",
      " 27%|██▋       | 184/673 [00:30<01:21,  5.97it/s]\u001b[A\n",
      " 27%|██▋       | 185/673 [00:30<01:21,  5.96it/s]\u001b[A\n",
      " 28%|██▊       | 186/673 [00:30<01:21,  5.94it/s]\u001b[A\n",
      " 28%|██▊       | 187/673 [00:30<01:21,  5.95it/s]\u001b[A\n",
      " 28%|██▊       | 188/673 [00:30<01:21,  5.94it/s]\u001b[A\n",
      " 28%|██▊       | 189/673 [00:31<01:22,  5.87it/s]\u001b[A\n",
      " 28%|██▊       | 190/673 [00:31<01:21,  5.90it/s]\u001b[A\n",
      " 28%|██▊       | 191/673 [00:31<01:21,  5.91it/s]\u001b[A\n",
      " 29%|██▊       | 192/673 [00:31<01:20,  5.95it/s]\u001b[A\n",
      " 29%|██▊       | 193/673 [00:31<01:20,  5.96it/s]\u001b[A\n",
      " 29%|██▉       | 194/673 [00:31<01:20,  5.94it/s]\u001b[A\n",
      " 29%|██▉       | 195/673 [00:32<01:20,  5.96it/s]\u001b[A\n",
      " 29%|██▉       | 196/673 [00:32<01:20,  5.94it/s]\u001b[A\n",
      " 29%|██▉       | 197/673 [00:32<01:20,  5.93it/s]\u001b[A\n",
      " 29%|██▉       | 198/673 [00:32<01:20,  5.93it/s]\u001b[A\n",
      " 30%|██▉       | 199/673 [00:32<01:19,  5.94it/s]\u001b[A\n",
      " 30%|██▉       | 200/673 [00:32<01:19,  5.96it/s]\u001b[A\n",
      " 30%|██▉       | 201/673 [00:33<01:19,  5.97it/s]\u001b[A\n",
      " 30%|███       | 202/673 [00:33<01:19,  5.95it/s]\u001b[A\n",
      " 30%|███       | 203/673 [00:33<01:19,  5.90it/s]\u001b[A\n",
      " 30%|███       | 204/673 [00:33<01:19,  5.87it/s]\u001b[A\n",
      " 30%|███       | 205/673 [00:33<01:19,  5.88it/s]\u001b[A\n",
      " 31%|███       | 206/673 [00:33<01:19,  5.91it/s]\u001b[A\n",
      " 31%|███       | 207/673 [00:34<01:19,  5.90it/s]\u001b[A\n",
      " 31%|███       | 208/673 [00:34<01:18,  5.92it/s]\u001b[A\n",
      " 31%|███       | 209/673 [00:34<01:18,  5.93it/s]\u001b[A\n",
      " 31%|███       | 210/673 [00:34<01:18,  5.93it/s]\u001b[A\n",
      " 31%|███▏      | 211/673 [00:34<01:17,  5.93it/s]\u001b[A\n",
      " 32%|███▏      | 212/673 [00:34<01:17,  5.92it/s]\u001b[A\n",
      " 32%|███▏      | 213/673 [00:35<01:17,  5.92it/s]\u001b[A\n",
      " 32%|███▏      | 214/673 [00:35<01:17,  5.89it/s]\u001b[A\n",
      " 32%|███▏      | 215/673 [00:35<01:17,  5.92it/s]\u001b[A\n",
      " 32%|███▏      | 216/673 [00:35<01:17,  5.88it/s]\u001b[A\n",
      " 32%|███▏      | 217/673 [00:35<01:17,  5.86it/s]\u001b[A\n",
      " 32%|███▏      | 218/673 [00:35<01:17,  5.88it/s]\u001b[A\n",
      " 33%|███▎      | 219/673 [00:36<01:17,  5.88it/s]\u001b[A\n",
      " 33%|███▎      | 220/673 [00:36<01:16,  5.89it/s]\u001b[A\n",
      " 33%|███▎      | 221/673 [00:36<01:18,  5.79it/s]\u001b[A\n",
      " 33%|███▎      | 222/673 [00:36<01:17,  5.82it/s]\u001b[A\n",
      " 33%|███▎      | 223/673 [00:36<01:16,  5.88it/s]\u001b[A\n",
      " 33%|███▎      | 224/673 [00:36<01:16,  5.91it/s]\u001b[A\n",
      " 33%|███▎      | 225/673 [00:37<01:16,  5.84it/s]\u001b[A\n",
      " 34%|███▎      | 226/673 [00:37<01:16,  5.83it/s]\u001b[A\n",
      " 34%|███▎      | 227/673 [00:37<01:16,  5.86it/s]\u001b[A\n",
      " 34%|███▍      | 228/673 [00:37<01:16,  5.84it/s]\u001b[A\n",
      " 34%|███▍      | 229/673 [00:37<01:16,  5.81it/s]\u001b[A\n",
      " 34%|███▍      | 230/673 [00:38<01:15,  5.84it/s]\u001b[A\n",
      " 34%|███▍      | 231/673 [00:38<01:15,  5.88it/s]\u001b[A\n",
      " 34%|███▍      | 232/673 [00:38<01:15,  5.86it/s]\u001b[A\n",
      " 35%|███▍      | 233/673 [00:38<01:14,  5.89it/s]\u001b[A\n",
      " 35%|███▍      | 234/673 [00:38<01:14,  5.86it/s]\u001b[A\n",
      " 35%|███▍      | 235/673 [00:38<01:15,  5.82it/s]\u001b[A\n",
      " 35%|███▌      | 236/673 [00:39<01:14,  5.83it/s]\u001b[A\n",
      " 35%|███▌      | 237/673 [00:39<01:15,  5.77it/s]\u001b[A\n",
      " 35%|███▌      | 238/673 [00:39<01:14,  5.81it/s]\u001b[A\n",
      " 36%|███▌      | 239/673 [00:39<01:14,  5.85it/s]\u001b[A\n",
      " 36%|███▌      | 240/673 [00:39<01:14,  5.84it/s]\u001b[A\n",
      " 36%|███▌      | 241/673 [00:39<01:14,  5.82it/s]\u001b[A\n",
      " 36%|███▌      | 242/673 [00:40<01:14,  5.79it/s]\u001b[A\n",
      " 36%|███▌      | 243/673 [00:40<01:14,  5.79it/s]\u001b[A\n",
      " 36%|███▋      | 244/673 [00:40<01:13,  5.84it/s]\u001b[A\n",
      " 36%|███▋      | 245/673 [00:40<01:13,  5.83it/s]\u001b[A\n",
      " 37%|███▋      | 246/673 [00:40<01:13,  5.85it/s]\u001b[A\n",
      " 37%|███▋      | 247/673 [00:40<01:12,  5.88it/s]\u001b[A\n",
      " 37%|███▋      | 248/673 [00:41<01:12,  5.82it/s]\u001b[A\n",
      " 37%|███▋      | 249/673 [00:41<01:12,  5.84it/s]\u001b[A\n",
      " 37%|███▋      | 250/673 [00:41<01:12,  5.82it/s]\u001b[A\n",
      " 37%|███▋      | 251/673 [00:41<01:12,  5.82it/s]\u001b[A\n",
      " 37%|███▋      | 252/673 [00:41<01:12,  5.82it/s]\u001b[A\n",
      " 38%|███▊      | 253/673 [00:41<01:11,  5.84it/s]\u001b[A\n",
      " 38%|███▊      | 254/673 [00:42<01:11,  5.85it/s]\u001b[A\n",
      " 38%|███▊      | 255/673 [00:42<01:11,  5.82it/s]\u001b[A\n",
      " 38%|███▊      | 256/673 [00:42<01:11,  5.84it/s]\u001b[A\n",
      " 38%|███▊      | 257/673 [00:42<01:10,  5.89it/s]\u001b[A\n",
      " 38%|███▊      | 258/673 [00:42<01:11,  5.84it/s]\u001b[A\n",
      " 38%|███▊      | 259/673 [00:42<01:10,  5.85it/s]\u001b[A\n",
      " 39%|███▊      | 260/673 [00:43<01:10,  5.86it/s]\u001b[A\n",
      " 39%|███▉      | 261/673 [00:43<01:10,  5.84it/s]\u001b[A\n",
      " 39%|███▉      | 262/673 [00:43<01:10,  5.82it/s]\u001b[A\n",
      " 39%|███▉      | 263/673 [00:43<01:10,  5.81it/s]\u001b[A\n",
      " 39%|███▉      | 264/673 [00:43<01:10,  5.82it/s]\u001b[A\n",
      " 39%|███▉      | 265/673 [00:44<01:10,  5.80it/s]\u001b[A\n",
      " 40%|███▉      | 266/673 [00:44<01:10,  5.80it/s]\u001b[A\n",
      " 40%|███▉      | 267/673 [00:44<01:10,  5.79it/s]\u001b[A\n",
      " 40%|███▉      | 268/673 [00:44<01:10,  5.78it/s]\u001b[A\n",
      " 40%|███▉      | 269/673 [00:44<01:10,  5.75it/s]\u001b[A\n",
      " 40%|████      | 270/673 [00:44<01:09,  5.79it/s]\u001b[A\n",
      " 40%|████      | 271/673 [00:45<01:09,  5.78it/s]\u001b[A\n",
      " 40%|████      | 272/673 [00:45<01:10,  5.69it/s]\u001b[A\n",
      " 41%|████      | 273/673 [00:45<01:09,  5.75it/s]\u001b[A\n",
      " 41%|████      | 274/673 [00:45<01:08,  5.80it/s]\u001b[A\n",
      " 41%|████      | 275/673 [00:45<01:08,  5.77it/s]\u001b[A\n",
      " 41%|████      | 276/673 [00:45<01:08,  5.79it/s]\u001b[A\n",
      " 41%|████      | 277/673 [00:46<01:08,  5.77it/s]\u001b[A\n",
      " 41%|████▏     | 278/673 [00:46<01:07,  5.81it/s]\u001b[A\n",
      " 41%|████▏     | 279/673 [00:46<01:07,  5.82it/s]\u001b[A\n",
      " 42%|████▏     | 280/673 [00:46<01:07,  5.84it/s]\u001b[A\n",
      " 42%|████▏     | 281/673 [00:46<01:07,  5.81it/s]\u001b[A\n",
      " 42%|████▏     | 282/673 [00:46<01:07,  5.77it/s]\u001b[A\n",
      " 42%|████▏     | 283/673 [00:47<01:07,  5.78it/s]\u001b[A\n",
      " 42%|████▏     | 284/673 [00:47<01:07,  5.80it/s]\u001b[A\n",
      " 42%|████▏     | 285/673 [00:47<01:06,  5.82it/s]\u001b[A\n",
      " 42%|████▏     | 286/673 [00:47<01:06,  5.79it/s]\u001b[A\n",
      " 43%|████▎     | 287/673 [00:47<01:06,  5.77it/s]\u001b[A\n",
      " 43%|████▎     | 288/673 [00:48<01:06,  5.77it/s]\u001b[A\n",
      " 43%|████▎     | 289/673 [00:48<01:06,  5.74it/s]\u001b[A\n",
      " 43%|████▎     | 290/673 [00:48<01:06,  5.74it/s]\u001b[A\n",
      " 43%|████▎     | 291/673 [00:48<01:06,  5.75it/s]\u001b[A\n",
      " 43%|████▎     | 292/673 [00:48<01:06,  5.73it/s]\u001b[A\n",
      " 44%|████▎     | 293/673 [00:48<01:06,  5.73it/s]\u001b[A\n",
      " 44%|████▎     | 294/673 [00:49<01:06,  5.73it/s]\u001b[A\n",
      " 44%|████▍     | 295/673 [00:49<01:05,  5.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 296/673 [00:49<01:06,  5.71it/s]\u001b[A\n",
      " 44%|████▍     | 297/673 [00:49<01:06,  5.69it/s]\u001b[A\n",
      " 44%|████▍     | 298/673 [00:49<01:05,  5.72it/s]\u001b[A\n",
      " 44%|████▍     | 299/673 [00:49<01:04,  5.76it/s]\u001b[A\n",
      " 45%|████▍     | 300/673 [00:50<01:04,  5.75it/s]\u001b[A\n",
      " 45%|████▍     | 301/673 [00:50<01:04,  5.74it/s]\u001b[A\n",
      " 45%|████▍     | 302/673 [00:50<01:04,  5.73it/s]\u001b[A\n",
      " 45%|████▌     | 303/673 [00:50<01:04,  5.74it/s]\u001b[A\n",
      " 45%|████▌     | 304/673 [00:50<01:04,  5.73it/s]\u001b[A\n",
      " 45%|████▌     | 305/673 [00:50<01:03,  5.77it/s]\u001b[A\n",
      " 45%|████▌     | 306/673 [00:51<01:03,  5.77it/s]\u001b[A\n",
      " 46%|████▌     | 307/673 [00:51<01:03,  5.79it/s]\u001b[A\n",
      " 46%|████▌     | 308/673 [00:51<01:03,  5.77it/s]\u001b[A\n",
      " 46%|████▌     | 309/673 [00:51<01:02,  5.79it/s]\u001b[A\n",
      " 46%|████▌     | 310/673 [00:51<01:02,  5.81it/s]\u001b[A\n",
      " 46%|████▌     | 311/673 [00:52<01:02,  5.79it/s]\u001b[A\n",
      " 46%|████▋     | 312/673 [00:52<01:02,  5.76it/s]\u001b[A\n",
      " 47%|████▋     | 313/673 [00:52<01:02,  5.72it/s]\u001b[A\n",
      " 47%|████▋     | 314/673 [00:52<01:02,  5.72it/s]\u001b[A\n",
      " 47%|████▋     | 315/673 [00:52<01:02,  5.72it/s]\u001b[A\n",
      " 47%|████▋     | 316/673 [00:52<01:02,  5.73it/s]\u001b[A\n",
      " 47%|████▋     | 317/673 [00:53<01:01,  5.75it/s]\u001b[A\n",
      " 47%|████▋     | 318/673 [00:53<01:01,  5.77it/s]\u001b[A\n",
      " 47%|████▋     | 319/673 [00:53<01:01,  5.78it/s]\u001b[A\n",
      " 48%|████▊     | 320/673 [00:53<01:01,  5.76it/s]\u001b[A\n",
      " 48%|████▊     | 321/673 [00:53<01:01,  5.73it/s]\u001b[A\n",
      " 48%|████▊     | 322/673 [00:53<01:01,  5.73it/s]\u001b[A\n",
      " 48%|████▊     | 323/673 [00:54<01:00,  5.75it/s]\u001b[A\n",
      " 48%|████▊     | 324/673 [00:54<01:00,  5.77it/s]\u001b[A\n",
      " 48%|████▊     | 325/673 [00:54<01:00,  5.78it/s]\u001b[A\n",
      " 48%|████▊     | 326/673 [00:54<00:59,  5.80it/s]\u001b[A\n",
      " 49%|████▊     | 327/673 [00:54<01:00,  5.73it/s]\u001b[A\n",
      " 49%|████▊     | 328/673 [00:54<00:59,  5.75it/s]\u001b[A\n",
      " 49%|████▉     | 329/673 [00:55<00:59,  5.77it/s]\u001b[A\n",
      " 49%|████▉     | 330/673 [00:55<01:00,  5.72it/s]\u001b[A\n",
      " 49%|████▉     | 331/673 [00:55<00:59,  5.73it/s]\u001b[A\n",
      " 49%|████▉     | 332/673 [00:55<00:59,  5.73it/s]\u001b[A\n",
      " 49%|████▉     | 333/673 [00:55<00:59,  5.74it/s]\u001b[A\n",
      " 50%|████▉     | 334/673 [00:56<00:58,  5.78it/s]\u001b[A\n",
      " 50%|████▉     | 335/673 [00:56<00:58,  5.76it/s]\u001b[A\n",
      " 50%|████▉     | 336/673 [00:56<00:57,  5.81it/s]\u001b[A\n",
      " 50%|█████     | 337/673 [00:56<00:58,  5.79it/s]\u001b[A\n",
      " 50%|█████     | 338/673 [00:56<00:57,  5.78it/s]\u001b[A\n",
      " 50%|█████     | 339/673 [00:56<00:57,  5.76it/s]\u001b[A\n",
      " 51%|█████     | 340/673 [00:57<00:57,  5.78it/s]\u001b[A\n",
      " 51%|█████     | 341/673 [00:57<00:57,  5.76it/s]\u001b[A\n",
      " 51%|█████     | 342/673 [00:57<00:57,  5.77it/s]\u001b[A\n",
      " 51%|█████     | 343/673 [00:57<00:57,  5.78it/s]\u001b[A\n",
      " 51%|█████     | 344/673 [00:57<00:56,  5.78it/s]\u001b[A\n",
      " 51%|█████▏    | 345/673 [00:57<00:56,  5.78it/s]\u001b[A\n",
      " 51%|█████▏    | 346/673 [00:58<00:56,  5.79it/s]\u001b[A\n",
      " 52%|█████▏    | 347/673 [00:58<00:56,  5.76it/s]\u001b[A\n",
      " 52%|█████▏    | 348/673 [00:58<00:56,  5.75it/s]\u001b[A\n",
      " 52%|█████▏    | 349/673 [00:58<00:56,  5.76it/s]\u001b[A\n",
      " 52%|█████▏    | 350/673 [00:58<00:56,  5.74it/s]\u001b[A\n",
      " 52%|█████▏    | 351/673 [00:58<00:56,  5.73it/s]\u001b[A\n",
      " 52%|█████▏    | 352/673 [00:59<00:56,  5.73it/s]\u001b[A\n",
      " 52%|█████▏    | 353/673 [00:59<00:56,  5.68it/s]\u001b[A\n",
      " 53%|█████▎    | 354/673 [00:59<00:56,  5.67it/s]\u001b[A\n",
      " 53%|█████▎    | 355/673 [00:59<00:55,  5.70it/s]\u001b[A\n",
      " 53%|█████▎    | 356/673 [00:59<00:55,  5.66it/s]\u001b[A\n",
      " 53%|█████▎    | 357/673 [01:00<00:55,  5.71it/s]\u001b[A\n",
      " 53%|█████▎    | 358/673 [01:00<00:54,  5.73it/s]\u001b[A\n",
      " 53%|█████▎    | 359/673 [01:00<00:54,  5.72it/s]\u001b[A\n",
      " 53%|█████▎    | 360/673 [01:00<00:55,  5.65it/s]\u001b[A\n",
      " 54%|█████▎    | 361/673 [01:00<00:55,  5.58it/s]\u001b[A\n",
      " 54%|█████▍    | 362/673 [01:00<00:55,  5.59it/s]\u001b[A\n",
      " 54%|█████▍    | 363/673 [01:01<00:54,  5.64it/s]\u001b[A\n",
      " 54%|█████▍    | 364/673 [01:01<00:54,  5.66it/s]\u001b[A\n",
      " 54%|█████▍    | 365/673 [01:01<00:54,  5.69it/s]\u001b[A\n",
      " 54%|█████▍    | 366/673 [01:01<00:53,  5.72it/s]\u001b[A\n",
      " 55%|█████▍    | 367/673 [01:01<00:53,  5.69it/s]\u001b[A\n",
      " 55%|█████▍    | 368/673 [01:01<00:53,  5.71it/s]\u001b[A\n",
      " 55%|█████▍    | 369/673 [01:02<00:53,  5.65it/s]\u001b[A\n",
      " 55%|█████▍    | 370/673 [01:02<00:53,  5.64it/s]\u001b[A\n",
      " 55%|█████▌    | 371/673 [01:02<00:52,  5.70it/s]\u001b[A\n",
      " 55%|█████▌    | 372/673 [01:02<00:52,  5.69it/s]\u001b[A\n",
      " 55%|█████▌    | 373/673 [01:02<00:52,  5.69it/s]\u001b[A\n",
      " 56%|█████▌    | 374/673 [01:03<00:52,  5.68it/s]\u001b[A\n",
      " 56%|█████▌    | 375/673 [01:03<00:52,  5.72it/s]\u001b[A\n",
      " 56%|█████▌    | 376/673 [01:03<00:52,  5.70it/s]\u001b[A\n",
      " 56%|█████▌    | 377/673 [01:03<00:51,  5.71it/s]\u001b[A\n",
      " 56%|█████▌    | 378/673 [01:03<00:52,  5.66it/s]\u001b[A\n",
      " 56%|█████▋    | 379/673 [01:03<00:52,  5.62it/s]\u001b[A\n",
      " 56%|█████▋    | 380/673 [01:04<00:52,  5.61it/s]\u001b[A\n",
      " 57%|█████▋    | 381/673 [01:04<00:51,  5.62it/s]\u001b[A\n",
      " 57%|█████▋    | 382/673 [01:04<00:51,  5.65it/s]\u001b[A\n",
      " 57%|█████▋    | 383/673 [01:04<00:50,  5.70it/s]\u001b[A\n",
      " 57%|█████▋    | 384/673 [01:04<00:50,  5.69it/s]\u001b[A\n",
      " 57%|█████▋    | 385/673 [01:04<00:50,  5.70it/s]\u001b[A\n",
      " 57%|█████▋    | 386/673 [01:05<00:50,  5.73it/s]\u001b[A\n",
      " 58%|█████▊    | 387/673 [01:05<00:50,  5.67it/s]\u001b[A\n",
      " 58%|█████▊    | 388/673 [01:05<00:50,  5.68it/s]\u001b[A\n",
      " 58%|█████▊    | 389/673 [01:05<00:49,  5.72it/s]\u001b[A\n",
      " 58%|█████▊    | 390/673 [01:05<00:50,  5.63it/s]\u001b[A\n",
      " 58%|█████▊    | 391/673 [01:06<00:50,  5.56it/s]\u001b[A\n",
      " 58%|█████▊    | 392/673 [01:06<00:50,  5.53it/s]\u001b[A\n",
      " 58%|█████▊    | 393/673 [01:06<00:50,  5.54it/s]\u001b[A\n",
      " 59%|█████▊    | 394/673 [01:06<00:49,  5.60it/s]\u001b[A\n",
      " 59%|█████▊    | 395/673 [01:06<00:49,  5.61it/s]\u001b[A\n",
      " 59%|█████▉    | 396/673 [01:06<00:49,  5.64it/s]\u001b[A\n",
      " 59%|█████▉    | 397/673 [01:07<00:48,  5.66it/s]\u001b[A\n",
      " 59%|█████▉    | 398/673 [01:07<00:49,  5.60it/s]\u001b[A\n",
      " 59%|█████▉    | 399/673 [01:07<00:48,  5.62it/s]\u001b[A\n",
      " 59%|█████▉    | 400/673 [01:07<00:48,  5.64it/s]\u001b[A\n",
      " 60%|█████▉    | 401/673 [01:07<00:48,  5.61it/s]\u001b[A\n",
      " 60%|█████▉    | 402/673 [01:07<00:48,  5.60it/s]\u001b[A\n",
      " 60%|█████▉    | 403/673 [01:08<00:48,  5.58it/s]\u001b[A\n",
      " 60%|██████    | 404/673 [01:08<00:47,  5.62it/s]\u001b[A\n",
      " 60%|██████    | 405/673 [01:08<00:47,  5.60it/s]\u001b[A\n",
      " 60%|██████    | 406/673 [01:08<00:47,  5.61it/s]\u001b[A\n",
      " 60%|██████    | 407/673 [01:08<00:47,  5.62it/s]\u001b[A\n",
      " 61%|██████    | 408/673 [01:09<00:47,  5.63it/s]\u001b[A\n",
      " 61%|██████    | 409/673 [01:09<00:46,  5.63it/s]\u001b[A\n",
      " 61%|██████    | 410/673 [01:09<00:46,  5.65it/s]\u001b[A\n",
      " 61%|██████    | 411/673 [01:09<00:46,  5.66it/s]\u001b[A\n",
      " 61%|██████    | 412/673 [01:09<00:46,  5.64it/s]\u001b[A\n",
      " 61%|██████▏   | 413/673 [01:09<00:46,  5.64it/s]\u001b[A\n",
      " 62%|██████▏   | 414/673 [01:10<00:46,  5.61it/s]\u001b[A\n",
      " 62%|██████▏   | 415/673 [01:10<00:46,  5.59it/s]\u001b[A\n",
      " 62%|██████▏   | 416/673 [01:10<00:45,  5.63it/s]\u001b[A\n",
      " 62%|██████▏   | 417/673 [01:10<00:45,  5.58it/s]\u001b[A\n",
      " 62%|██████▏   | 418/673 [01:10<00:45,  5.56it/s]\u001b[A\n",
      " 62%|██████▏   | 419/673 [01:11<00:45,  5.60it/s]\u001b[A\n",
      " 62%|██████▏   | 420/673 [01:11<00:45,  5.59it/s]\u001b[A\n",
      " 63%|██████▎   | 421/673 [01:11<00:45,  5.55it/s]\u001b[A\n",
      " 63%|██████▎   | 422/673 [01:11<00:45,  5.56it/s]\u001b[A\n",
      " 63%|██████▎   | 423/673 [01:11<00:44,  5.61it/s]\u001b[A\n",
      " 63%|██████▎   | 424/673 [01:11<00:44,  5.61it/s]\u001b[A\n",
      " 63%|██████▎   | 425/673 [01:12<00:44,  5.55it/s]\u001b[A\n",
      " 63%|██████▎   | 426/673 [01:12<00:44,  5.56it/s]\u001b[A\n",
      " 63%|██████▎   | 427/673 [01:12<00:44,  5.58it/s]\u001b[A\n",
      " 64%|██████▎   | 428/673 [01:12<00:43,  5.61it/s]\u001b[A\n",
      " 64%|██████▎   | 429/673 [01:12<00:43,  5.63it/s]\u001b[A\n",
      " 64%|██████▍   | 430/673 [01:12<00:42,  5.66it/s]\u001b[A\n",
      " 64%|██████▍   | 431/673 [01:13<00:42,  5.65it/s]\u001b[A\n",
      " 64%|██████▍   | 432/673 [01:13<00:43,  5.58it/s]\u001b[A\n",
      " 64%|██████▍   | 433/673 [01:13<00:43,  5.51it/s]\u001b[A\n",
      " 64%|██████▍   | 434/673 [01:13<00:43,  5.52it/s]\u001b[A\n",
      " 65%|██████▍   | 435/673 [01:13<00:43,  5.50it/s]\u001b[A\n",
      " 65%|██████▍   | 436/673 [01:14<00:42,  5.51it/s]\u001b[A\n",
      " 65%|██████▍   | 437/673 [01:14<00:42,  5.54it/s]\u001b[A\n",
      " 65%|██████▌   | 438/673 [01:14<00:42,  5.59it/s]\u001b[A\n",
      " 65%|██████▌   | 439/673 [01:14<00:41,  5.59it/s]\u001b[A\n",
      " 65%|██████▌   | 440/673 [01:14<00:41,  5.66it/s]\u001b[A\n",
      " 66%|██████▌   | 441/673 [01:14<00:41,  5.63it/s]\u001b[A\n",
      " 66%|██████▌   | 442/673 [01:15<00:41,  5.61it/s]\u001b[A\n",
      " 66%|██████▌   | 443/673 [01:15<00:41,  5.49it/s]\u001b[A\n",
      " 66%|██████▌   | 444/673 [01:15<00:41,  5.53it/s]\u001b[A\n",
      " 66%|██████▌   | 445/673 [01:15<00:41,  5.55it/s]\u001b[A\n",
      " 66%|██████▋   | 446/673 [01:15<00:41,  5.53it/s]\u001b[A\n",
      " 66%|██████▋   | 447/673 [01:16<00:40,  5.53it/s]\u001b[A\n",
      " 67%|██████▋   | 448/673 [01:16<00:40,  5.50it/s]\u001b[A\n",
      " 67%|██████▋   | 449/673 [01:16<00:40,  5.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 450/673 [01:16<00:40,  5.51it/s]\u001b[A\n",
      " 67%|██████▋   | 451/673 [01:16<00:40,  5.53it/s]\u001b[A\n",
      " 67%|██████▋   | 452/673 [01:16<00:39,  5.54it/s]\u001b[A\n",
      " 67%|██████▋   | 453/673 [01:17<00:40,  5.50it/s]\u001b[A\n",
      " 67%|██████▋   | 454/673 [01:17<00:39,  5.48it/s]\u001b[A\n",
      " 68%|██████▊   | 455/673 [01:17<00:39,  5.49it/s]\u001b[A\n",
      " 68%|██████▊   | 456/673 [01:17<00:39,  5.51it/s]\u001b[A\n",
      " 68%|██████▊   | 457/673 [01:17<00:39,  5.46it/s]\u001b[A\n",
      " 68%|██████▊   | 458/673 [01:18<00:38,  5.52it/s]\u001b[A\n",
      " 68%|██████▊   | 459/673 [01:18<00:38,  5.53it/s]\u001b[A\n",
      " 68%|██████▊   | 460/673 [01:18<00:38,  5.48it/s]\u001b[A\n",
      " 68%|██████▊   | 461/673 [01:18<00:38,  5.50it/s]\u001b[A\n",
      " 69%|██████▊   | 462/673 [01:18<00:38,  5.49it/s]\u001b[A\n",
      " 69%|██████▉   | 463/673 [01:18<00:37,  5.55it/s]\u001b[A\n",
      " 69%|██████▉   | 464/673 [01:19<00:37,  5.57it/s]\u001b[A\n",
      " 69%|██████▉   | 465/673 [01:19<00:37,  5.56it/s]\u001b[A\n",
      " 69%|██████▉   | 466/673 [01:19<00:37,  5.59it/s]\u001b[A\n",
      " 69%|██████▉   | 467/673 [01:19<00:36,  5.60it/s]\u001b[A\n",
      " 70%|██████▉   | 468/673 [01:19<00:36,  5.59it/s]\u001b[A\n",
      " 70%|██████▉   | 469/673 [01:20<00:36,  5.57it/s]\u001b[A\n",
      " 70%|██████▉   | 470/673 [01:20<00:36,  5.52it/s]\u001b[A\n",
      " 70%|██████▉   | 471/673 [01:20<00:37,  5.46it/s]\u001b[A\n",
      " 70%|███████   | 472/673 [01:20<00:36,  5.47it/s]\u001b[A\n",
      " 70%|███████   | 473/673 [01:20<00:36,  5.50it/s]\u001b[A\n",
      " 70%|███████   | 474/673 [01:20<00:36,  5.51it/s]\u001b[A\n",
      " 71%|███████   | 475/673 [01:21<00:35,  5.53it/s]\u001b[A\n",
      " 71%|███████   | 476/673 [01:21<00:35,  5.54it/s]\u001b[A\n",
      " 71%|███████   | 477/673 [01:21<00:35,  5.50it/s]\u001b[A\n",
      " 71%|███████   | 478/673 [01:21<00:35,  5.49it/s]\u001b[A\n",
      " 71%|███████   | 479/673 [01:21<00:35,  5.45it/s]\u001b[A\n",
      " 71%|███████▏  | 480/673 [01:22<00:35,  5.42it/s]\u001b[A\n",
      " 71%|███████▏  | 481/673 [01:22<00:35,  5.41it/s]\u001b[A\n",
      " 72%|███████▏  | 482/673 [01:22<00:35,  5.38it/s]\u001b[A\n",
      " 72%|███████▏  | 483/673 [01:22<00:35,  5.41it/s]\u001b[A\n",
      " 72%|███████▏  | 484/673 [01:22<00:34,  5.47it/s]\u001b[A\n",
      " 72%|███████▏  | 485/673 [01:22<00:34,  5.50it/s]\u001b[A\n",
      " 72%|███████▏  | 486/673 [01:23<00:33,  5.55it/s]\u001b[A\n",
      " 72%|███████▏  | 487/673 [01:23<00:33,  5.58it/s]\u001b[A\n",
      " 73%|███████▎  | 488/673 [01:23<00:33,  5.59it/s]\u001b[A\n",
      " 73%|███████▎  | 489/673 [01:23<00:32,  5.58it/s]\u001b[A\n",
      " 73%|███████▎  | 490/673 [01:23<00:32,  5.55it/s]\u001b[A\n",
      " 73%|███████▎  | 491/673 [01:24<00:32,  5.54it/s]\u001b[A\n",
      " 73%|███████▎  | 492/673 [01:24<00:32,  5.52it/s]\u001b[A\n",
      " 73%|███████▎  | 493/673 [01:24<00:32,  5.54it/s]\u001b[A\n",
      " 73%|███████▎  | 494/673 [01:24<00:32,  5.50it/s]\u001b[A\n",
      " 74%|███████▎  | 495/673 [01:24<00:32,  5.45it/s]\u001b[A\n",
      " 74%|███████▎  | 496/673 [01:24<00:32,  5.43it/s]\u001b[A\n",
      " 74%|███████▍  | 497/673 [01:25<00:32,  5.43it/s]\u001b[A\n",
      " 74%|███████▍  | 498/673 [01:25<00:32,  5.41it/s]\u001b[A\n",
      " 74%|███████▍  | 499/673 [01:25<00:31,  5.46it/s]\u001b[A\n",
      " 74%|███████▍  | 500/673 [01:25<00:31,  5.47it/s]\u001b[A\n",
      " 74%|███████▍  | 501/673 [01:25<00:31,  5.48it/s]\u001b[A\n",
      " 75%|███████▍  | 502/673 [01:26<00:31,  5.49it/s]\u001b[A\n",
      " 75%|███████▍  | 503/673 [01:26<00:30,  5.51it/s]\u001b[A\n",
      " 75%|███████▍  | 504/673 [01:26<00:30,  5.50it/s]\u001b[A\n",
      " 75%|███████▌  | 505/673 [01:26<00:30,  5.50it/s]\u001b[A\n",
      " 75%|███████▌  | 506/673 [01:26<00:30,  5.51it/s]\u001b[A\n",
      " 75%|███████▌  | 507/673 [01:26<00:30,  5.53it/s]\u001b[A\n",
      " 75%|███████▌  | 508/673 [01:27<00:29,  5.52it/s]\u001b[A\n",
      " 76%|███████▌  | 509/673 [01:27<00:29,  5.48it/s]\u001b[A\n",
      " 76%|███████▌  | 510/673 [01:27<00:29,  5.51it/s]\u001b[A\n",
      " 76%|███████▌  | 511/673 [01:27<00:29,  5.53it/s]\u001b[A\n",
      " 76%|███████▌  | 512/673 [01:27<00:29,  5.51it/s]\u001b[A\n",
      " 76%|███████▌  | 513/673 [01:28<00:29,  5.47it/s]\u001b[A\n",
      " 76%|███████▋  | 514/673 [01:28<00:29,  5.45it/s]\u001b[A\n",
      " 77%|███████▋  | 515/673 [01:28<00:28,  5.45it/s]\u001b[A\n",
      " 77%|███████▋  | 516/673 [01:28<00:28,  5.48it/s]\u001b[A\n",
      " 77%|███████▋  | 517/673 [01:28<00:28,  5.48it/s]\u001b[A\n",
      " 77%|███████▋  | 518/673 [01:28<00:28,  5.47it/s]\u001b[A\n",
      " 77%|███████▋  | 519/673 [01:29<00:28,  5.49it/s]\u001b[A\n",
      " 77%|███████▋  | 520/673 [01:29<00:28,  5.43it/s]\u001b[A\n",
      " 77%|███████▋  | 521/673 [01:29<00:27,  5.44it/s]\u001b[A\n",
      " 78%|███████▊  | 522/673 [01:29<00:27,  5.45it/s]\u001b[A\n",
      " 78%|███████▊  | 523/673 [01:29<00:27,  5.45it/s]\u001b[A\n",
      " 78%|███████▊  | 524/673 [01:30<00:27,  5.42it/s]\u001b[A\n",
      " 78%|███████▊  | 525/673 [01:30<00:27,  5.45it/s]\u001b[A\n",
      " 78%|███████▊  | 526/673 [01:30<00:26,  5.46it/s]\u001b[A\n",
      " 78%|███████▊  | 527/673 [01:30<00:26,  5.48it/s]\u001b[A\n",
      " 78%|███████▊  | 528/673 [01:30<00:26,  5.50it/s]\u001b[A\n",
      " 79%|███████▊  | 529/673 [01:30<00:26,  5.44it/s]\u001b[A\n",
      " 79%|███████▉  | 530/673 [01:31<00:26,  5.47it/s]\u001b[A\n",
      " 79%|███████▉  | 531/673 [01:31<00:26,  5.42it/s]\u001b[A\n",
      " 79%|███████▉  | 532/673 [01:31<00:25,  5.43it/s]\u001b[A\n",
      " 79%|███████▉  | 533/673 [01:31<00:25,  5.44it/s]\u001b[A\n",
      " 79%|███████▉  | 534/673 [01:31<00:25,  5.44it/s]\u001b[A\n",
      " 79%|███████▉  | 535/673 [01:32<00:25,  5.48it/s]\u001b[A\n",
      " 80%|███████▉  | 536/673 [01:32<00:24,  5.51it/s]\u001b[A\n",
      " 80%|███████▉  | 537/673 [01:32<00:24,  5.52it/s]\u001b[A\n",
      " 80%|███████▉  | 538/673 [01:32<00:24,  5.49it/s]\u001b[A\n",
      " 80%|████████  | 539/673 [01:32<00:24,  5.48it/s]\u001b[A\n",
      " 80%|████████  | 540/673 [01:32<00:24,  5.49it/s]\u001b[A\n",
      " 80%|████████  | 541/673 [01:33<00:24,  5.49it/s]\u001b[A\n",
      " 81%|████████  | 542/673 [01:33<00:24,  5.45it/s]\u001b[A\n",
      " 81%|████████  | 543/673 [01:33<00:23,  5.47it/s]\u001b[A\n",
      " 81%|████████  | 544/673 [01:33<00:23,  5.46it/s]\u001b[A\n",
      " 81%|████████  | 545/673 [01:33<00:23,  5.44it/s]\u001b[A\n",
      " 81%|████████  | 546/673 [01:34<00:23,  5.43it/s]\u001b[A\n",
      " 81%|████████▏ | 547/673 [01:34<00:23,  5.43it/s]\u001b[A\n",
      " 81%|████████▏ | 548/673 [01:34<00:23,  5.40it/s]\u001b[A\n",
      " 82%|████████▏ | 549/673 [01:34<00:22,  5.41it/s]\u001b[A\n",
      " 82%|████████▏ | 550/673 [01:34<00:22,  5.42it/s]\u001b[A\n",
      " 82%|████████▏ | 551/673 [01:35<00:22,  5.43it/s]\u001b[A\n",
      " 82%|████████▏ | 552/673 [01:35<00:22,  5.42it/s]\u001b[A\n",
      " 82%|████████▏ | 553/673 [01:35<00:22,  5.41it/s]\u001b[A\n",
      " 82%|████████▏ | 554/673 [01:35<00:21,  5.41it/s]\u001b[A\n",
      " 82%|████████▏ | 555/673 [01:35<00:21,  5.41it/s]\u001b[A\n",
      " 83%|████████▎ | 556/673 [01:35<00:21,  5.38it/s]\u001b[A\n",
      " 83%|████████▎ | 557/673 [01:36<00:21,  5.38it/s]\u001b[A\n",
      " 83%|████████▎ | 558/673 [01:36<00:21,  5.39it/s]\u001b[A\n",
      " 83%|████████▎ | 559/673 [01:36<00:21,  5.41it/s]\u001b[A\n",
      " 83%|████████▎ | 560/673 [01:36<00:20,  5.40it/s]\u001b[A\n",
      " 83%|████████▎ | 561/673 [01:36<00:20,  5.39it/s]\u001b[A\n",
      " 84%|████████▎ | 562/673 [01:37<00:20,  5.37it/s]\u001b[A\n",
      " 84%|████████▎ | 563/673 [01:37<00:20,  5.38it/s]\u001b[A\n",
      " 84%|████████▍ | 564/673 [01:37<00:20,  5.37it/s]\u001b[A\n",
      " 84%|████████▍ | 565/673 [01:37<00:20,  5.39it/s]\u001b[A\n",
      " 84%|████████▍ | 566/673 [01:37<00:19,  5.37it/s]\u001b[A\n",
      " 84%|████████▍ | 567/673 [01:37<00:19,  5.40it/s]\u001b[A\n",
      " 84%|████████▍ | 568/673 [01:38<00:19,  5.43it/s]\u001b[A\n",
      " 85%|████████▍ | 569/673 [01:38<00:19,  5.43it/s]\u001b[A\n",
      " 85%|████████▍ | 570/673 [01:38<00:19,  5.37it/s]\u001b[A\n",
      " 85%|████████▍ | 571/673 [01:38<00:19,  5.34it/s]\u001b[A\n",
      " 85%|████████▍ | 572/673 [01:38<00:19,  5.30it/s]\u001b[A\n",
      " 85%|████████▌ | 573/673 [01:39<00:18,  5.32it/s]\u001b[A\n",
      " 85%|████████▌ | 574/673 [01:39<00:18,  5.32it/s]\u001b[A\n",
      " 85%|████████▌ | 575/673 [01:39<00:18,  5.31it/s]\u001b[A\n",
      " 86%|████████▌ | 576/673 [01:39<00:18,  5.36it/s]\u001b[A\n",
      " 86%|████████▌ | 577/673 [01:39<00:17,  5.33it/s]\u001b[A\n",
      " 86%|████████▌ | 578/673 [01:40<00:17,  5.37it/s]\u001b[A\n",
      " 86%|████████▌ | 579/673 [01:40<00:17,  5.37it/s]\u001b[A\n",
      " 86%|████████▌ | 580/673 [01:40<00:17,  5.30it/s]\u001b[A\n",
      " 86%|████████▋ | 581/673 [01:40<00:17,  5.32it/s]\u001b[A\n",
      " 86%|████████▋ | 582/673 [01:40<00:16,  5.35it/s]\u001b[A\n",
      " 87%|████████▋ | 583/673 [01:40<00:16,  5.34it/s]\u001b[A\n",
      " 87%|████████▋ | 584/673 [01:41<00:16,  5.30it/s]\u001b[A\n",
      " 87%|████████▋ | 585/673 [01:41<00:16,  5.32it/s]\u001b[A\n",
      " 87%|████████▋ | 586/673 [01:41<00:16,  5.35it/s]\u001b[A\n",
      " 87%|████████▋ | 587/673 [01:41<00:16,  5.32it/s]\u001b[A\n",
      " 87%|████████▋ | 588/673 [01:41<00:16,  5.31it/s]\u001b[A\n",
      " 88%|████████▊ | 589/673 [01:42<00:15,  5.29it/s]\u001b[A\n",
      " 88%|████████▊ | 590/673 [01:42<00:15,  5.31it/s]\u001b[A\n",
      " 88%|████████▊ | 591/673 [01:42<00:15,  5.36it/s]\u001b[A\n",
      " 88%|████████▊ | 592/673 [01:42<00:15,  5.37it/s]\u001b[A\n",
      " 88%|████████▊ | 593/673 [01:42<00:14,  5.36it/s]\u001b[A\n",
      " 88%|████████▊ | 594/673 [01:43<00:14,  5.37it/s]\u001b[A\n",
      " 88%|████████▊ | 595/673 [01:43<00:14,  5.36it/s]\u001b[A\n",
      " 89%|████████▊ | 596/673 [01:43<00:14,  5.36it/s]\u001b[A\n",
      " 89%|████████▊ | 597/673 [01:43<00:14,  5.35it/s]\u001b[A\n",
      " 89%|████████▉ | 598/673 [01:43<00:14,  5.34it/s]\u001b[A\n",
      " 89%|████████▉ | 599/673 [01:43<00:13,  5.35it/s]\u001b[A\n",
      " 89%|████████▉ | 600/673 [01:44<00:13,  5.36it/s]\u001b[A\n",
      " 89%|████████▉ | 601/673 [01:44<00:13,  5.36it/s]\u001b[A\n",
      " 89%|████████▉ | 602/673 [01:44<00:13,  5.38it/s]\u001b[A\n",
      " 90%|████████▉ | 603/673 [01:44<00:13,  5.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 604/673 [01:44<00:12,  5.33it/s]\u001b[A\n",
      " 90%|████████▉ | 605/673 [01:45<00:12,  5.32it/s]\u001b[A\n",
      " 90%|█████████ | 606/673 [01:45<00:12,  5.24it/s]\u001b[A\n",
      " 90%|█████████ | 607/673 [01:45<00:12,  5.21it/s]\u001b[A\n",
      " 90%|█████████ | 608/673 [01:45<00:12,  5.20it/s]\u001b[A\n",
      " 90%|█████████ | 609/673 [01:45<00:12,  5.18it/s]\u001b[A\n",
      " 91%|█████████ | 610/673 [01:46<00:12,  5.14it/s]\u001b[A\n",
      " 91%|█████████ | 611/673 [01:46<00:11,  5.18it/s]\u001b[A\n",
      " 91%|█████████ | 612/673 [01:46<00:11,  5.18it/s]\u001b[A\n",
      " 91%|█████████ | 613/673 [01:46<00:11,  5.21it/s]\u001b[A\n",
      " 91%|█████████ | 614/673 [01:46<00:11,  5.23it/s]\u001b[A\n",
      " 91%|█████████▏| 615/673 [01:47<00:11,  5.23it/s]\u001b[A\n",
      " 92%|█████████▏| 616/673 [01:47<00:10,  5.25it/s]\u001b[A\n",
      " 92%|█████████▏| 617/673 [01:47<00:10,  5.24it/s]\u001b[A\n",
      " 92%|█████████▏| 618/673 [01:47<00:10,  5.24it/s]\u001b[A\n",
      " 92%|█████████▏| 619/673 [01:47<00:10,  5.25it/s]\u001b[A\n",
      " 92%|█████████▏| 620/673 [01:47<00:10,  5.24it/s]\u001b[A\n",
      " 92%|█████████▏| 621/673 [01:48<00:09,  5.24it/s]\u001b[A\n",
      " 92%|█████████▏| 622/673 [01:48<00:09,  5.28it/s]\u001b[A\n",
      " 93%|█████████▎| 623/673 [01:48<00:09,  5.27it/s]\u001b[A\n",
      " 93%|█████████▎| 624/673 [01:48<00:09,  5.27it/s]\u001b[A\n",
      " 93%|█████████▎| 625/673 [01:48<00:09,  5.28it/s]\u001b[A\n",
      " 93%|█████████▎| 626/673 [01:49<00:08,  5.27it/s]\u001b[A\n",
      " 93%|█████████▎| 627/673 [01:49<00:08,  5.26it/s]\u001b[A\n",
      " 93%|█████████▎| 628/673 [01:49<00:08,  5.26it/s]\u001b[A\n",
      " 93%|█████████▎| 629/673 [01:49<00:08,  5.26it/s]\u001b[A\n",
      " 94%|█████████▎| 630/673 [01:49<00:08,  5.27it/s]\u001b[A\n",
      " 94%|█████████▍| 631/673 [01:50<00:07,  5.26it/s]\u001b[A\n",
      " 94%|█████████▍| 632/673 [01:50<00:07,  5.26it/s]\u001b[A\n",
      " 94%|█████████▍| 633/673 [01:50<00:07,  5.25it/s]\u001b[A\n",
      " 94%|█████████▍| 634/673 [01:50<00:07,  5.26it/s]\u001b[A\n",
      " 94%|█████████▍| 635/673 [01:50<00:07,  5.27it/s]\u001b[A\n",
      " 95%|█████████▍| 636/673 [01:51<00:06,  5.30it/s]\u001b[A\n",
      " 95%|█████████▍| 637/673 [01:51<00:06,  5.32it/s]\u001b[A\n",
      " 95%|█████████▍| 638/673 [01:51<00:06,  5.29it/s]\u001b[A\n",
      " 95%|█████████▍| 639/673 [01:51<00:06,  5.28it/s]\u001b[A\n",
      " 95%|█████████▌| 640/673 [01:51<00:06,  5.26it/s]\u001b[A\n",
      " 95%|█████████▌| 641/673 [01:51<00:06,  5.27it/s]\u001b[A\n",
      " 95%|█████████▌| 642/673 [01:52<00:05,  5.21it/s]\u001b[A\n",
      " 96%|█████████▌| 643/673 [01:52<00:05,  5.18it/s]\u001b[A\n",
      " 96%|█████████▌| 644/673 [01:52<00:05,  5.21it/s]\u001b[A\n",
      " 96%|█████████▌| 645/673 [01:52<00:05,  5.21it/s]\u001b[A\n",
      " 96%|█████████▌| 646/673 [01:52<00:05,  5.24it/s]\u001b[A\n",
      " 96%|█████████▌| 647/673 [01:53<00:04,  5.23it/s]\u001b[A\n",
      " 96%|█████████▋| 648/673 [01:53<00:04,  5.23it/s]\u001b[A\n",
      " 96%|█████████▋| 649/673 [01:53<00:04,  5.29it/s]\u001b[A\n",
      " 97%|█████████▋| 650/673 [01:53<00:04,  5.28it/s]\u001b[A\n",
      " 97%|█████████▋| 651/673 [01:53<00:04,  5.22it/s]\u001b[A\n",
      " 97%|█████████▋| 652/673 [01:54<00:04,  5.20it/s]\u001b[A\n",
      " 97%|█████████▋| 653/673 [01:54<00:03,  5.20it/s]\u001b[A\n",
      " 97%|█████████▋| 654/673 [01:54<00:03,  5.14it/s]\u001b[A\n",
      " 97%|█████████▋| 655/673 [01:54<00:03,  5.16it/s]\u001b[A\n",
      " 97%|█████████▋| 656/673 [01:54<00:03,  5.12it/s]\u001b[A\n",
      " 98%|█████████▊| 657/673 [01:55<00:03,  5.12it/s]\u001b[A\n",
      " 98%|█████████▊| 658/673 [01:55<00:02,  5.13it/s]\u001b[A\n",
      " 98%|█████████▊| 659/673 [01:55<00:02,  5.16it/s]\u001b[A\n",
      " 98%|█████████▊| 660/673 [01:55<00:02,  5.20it/s]\u001b[A\n",
      " 98%|█████████▊| 661/673 [01:55<00:02,  5.19it/s]\u001b[A\n",
      " 98%|█████████▊| 662/673 [01:56<00:02,  5.06it/s]\u001b[A\n",
      " 99%|█████████▊| 663/673 [01:56<00:01,  5.09it/s]\u001b[A\n",
      " 99%|█████████▊| 664/673 [01:56<00:01,  5.09it/s]\u001b[A\n",
      " 99%|█████████▉| 665/673 [01:56<00:01,  5.11it/s]\u001b[A\n",
      " 99%|█████████▉| 666/673 [01:56<00:01,  5.17it/s]\u001b[A\n",
      " 99%|█████████▉| 667/673 [01:56<00:01,  5.19it/s]\u001b[A\n",
      " 99%|█████████▉| 668/673 [01:57<00:00,  5.22it/s]\u001b[A\n",
      " 99%|█████████▉| 669/673 [01:57<00:00,  5.21it/s]\u001b[A\n",
      "100%|█████████▉| 670/673 [01:57<00:00,  5.19it/s]\u001b[A\n",
      "100%|█████████▉| 671/673 [01:57<00:00,  5.16it/s]\u001b[A\n",
      "100%|█████████▉| 672/673 [01:57<00:00,  5.17it/s]\u001b[A\n",
      "100%|██████████| 673/673 [01:58<00:00,  5.20it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for v_fn in input_videos:\n",
    "    process_video(v_fn, out_dir, out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
